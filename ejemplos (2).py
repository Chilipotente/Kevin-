# -*- coding: utf-8 -*-
"""ejemplos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yTFE68J3hY5bbPoxW3HCyhCMlG9UDxd-
"""

from pyspark.context import SparkContext

sc = SparkContext('local', 'test')

vars = sc.parallelize([("x", 1), ("y", 4)])

vars_2 = sc.parallelize([("x", 2), ("y", 3)])

sorted(vars.join(vars_2).collect())

sc.range(4).collect()

sc.parallelize(["x", "y"]).collect()

vars = sc.parallelize([("x", 1), ("y", 1), ("x", 2)])

sorted(vars.groupByKey().mapValues(len).collect())
[('x', 2), ('y', 1)]

from operator import add

vars = sc.parallelize([("x", 1), ("y", 3), ("x", 1)])

sorted(vars.reduceByKey(add).collect())

tmp = [('x', 1), ('y', 2), ('x', 3), ('x', 4), ('y', 5)]

sc.parallelize(tmp).sortByKey(True, 1).collect()

vars = sc.parallelize([("x", 1), ("y", 4)])

vars_2 = sc.parallelize([("a", 2)])

[(x, tuple(map(list, y))) for x, y in sorted(list(vars.cogroup(vars_2).collect()))]
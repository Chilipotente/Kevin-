# -*- coding: utf-8 -*-
"""ejemplos_xander.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WnUkU5jA-D8FFZ2ZudlP_x5oDB8mHYyU
"""

from pyspark.context import SparkContext

sc = SparkContext('local', 'test')

sc2 = SparkContext('local', 'test2')

sc2.stop()

var = sc.parallelize(["b", "a", "c"])

var.map(lambda x: (x, 1)).collect()

var_context = var.map(lambda x: (x, 1))

var_context.collect()

rdd_1 = sc.parallelize([1, 1, 2, 3])

rdd_2 = sc.parallelize([6, 7, 8, 9])

var_general = rdd_1.union(rdd_2)

var_general.collect()

var_general = rdd_1.union(rdd_1)

var_general.collect()

from pyspark.context import SparkContext

rex_1 = sc.parallelize([6, 20, 25, 9, 7, 63])

rex_2 = sc.parallelize([8, 20, 30, 9, 70, 63])

rex_general = rex_1.intersection(rex_2)

rex_general.reduce(lambda x, y: x + y)

rex_general.collect()

XA = sc.parallelize([("1", ["6", "7", "8"]), ("2", ["9", "10"])])

XA.flatMapValues(f).collect()